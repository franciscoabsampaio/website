[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About Me",
    "section": "",
    "text": "Hi!\nI‚Äôm Francisco and this is my personal blog/website, where I‚Äôll be sharing technical tutorials, thoughts, and whatever I see fit!\nFeel free to look around!"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Tutorial: Reproducible Spark+Delta Tests Without the Hassle\n\n\n\nspark\n\ndelta\n\ndocker\n\n\n\n\n\n\n\n\n\nOct 23, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nTransformers Maketh LLMs\n\n\n\ntransformer\n\nllm\n\nnlp\n\n\n\n\n\n\n\n\n\nJun 1, 2025\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/2025-tutorial-spark-connect/index.html",
    "href": "blog/2025-tutorial-spark-connect/index.html",
    "title": "Tutorial: Reproducible Spark+Delta Tests Without the Hassle",
    "section": "",
    "text": "Pre-requisite: if you‚Äôre not familiar with Docker, I recommend you follow the official introductory guide.\nSetting up a Spark instance can be quite the hassle. Add a data catalog like Delta or Apache Iceberg, and the complexity blows up!\nBut testing catalog-specific queries against a Spark instance should be easy. And, if you‚Äôre an automation nerd like myself, it should be reproducible, as well.\nUnfortunately, the traditional method of installing the OpenJDK, JVM, Spark drivers, Hive plugins, Delta jars is anything but easy, let alone reproducible (As a matter of fact, on the eve of publishing this article, the Live Notebooks on PySpark‚Äôs official quickstart page failed to launch due to a bug downloading OpenJDK‚Ä¶ üòÖ).\nFaced with this problem, I decided to take matters into my own hands ‚Äî and published a Docker Hub repository for running Spark Connect servers!"
  },
  {
    "objectID": "blog/2025-tutorial-spark-connect/index.html#running-the-container",
    "href": "blog/2025-tutorial-spark-connect/index.html#running-the-container",
    "title": "Tutorial: Reproducible Spark+Delta Tests Without the Hassle",
    "section": "Running the Container",
    "text": "Running the Container\nRunning it is as straight-forward as any other container. Simply:\ndocker run -p 15002:15002 franciscoabsampaio/spark-connect-server:delta\nWe use the ‚Äúdelta‚Äù tag if we wish to spin the server with a Delta catalog, and the ‚Äúiceberg‚Äù tag for the Iceberg catalog.\nThe docker run command will pull the image, and start it, resulting in a generous slew of logs, ending with a message akin to ‚ÄúSpark Connect server started at 0.0.0.0:15002‚Äù ‚Äî letting us know that the Spark instance is LIVE and ready to accept connections.\nNow, connecting to it in PySpark is as easy as:\nfrom pyspark.sql import SparkSession\n\nspark = SparkSession.builder \\\n    .remote(\"sc://localhost:15002\") \\\n    .getOrCreate()\n\n# A simple check:\ndf = spark.sql(f\"SELECT 1 AS id\")\nrows = df.collect()\n\nprint(rows)\n\nNote: You may have to install Python packages grpcio, grpcio-status and protobuf for pyspark to connect successfully.\n\nThe Spark session is ON and completely functional for all you development needs."
  },
  {
    "objectID": "blog/2025-tutorial-spark-connect/index.html#spark-connect",
    "href": "blog/2025-tutorial-spark-connect/index.html#spark-connect",
    "title": "Tutorial: Reproducible Spark+Delta Tests Without the Hassle",
    "section": "Spark Connect",
    "text": "Spark Connect\nSpark Connect is Apache‚Äôs newest gRPC protocol for Apache Spark. It lets any client that implements the Spark Connect protocol to connect to a Spark Server, and execute workloads seamlessly.\nWhat this Docker container does is take care of all the setup for launching a Spark instance with Spark Connect server, to make the development experience as smooth as possible."
  },
  {
    "objectID": "blog/2025-tutorial-spark-connect/index.html#reproducible-tests",
    "href": "blog/2025-tutorial-spark-connect/index.html#reproducible-tests",
    "title": "Tutorial: Reproducible Spark+Delta Tests Without the Hassle",
    "section": "Reproducible Tests",
    "text": "Reproducible Tests\nIf you‚Äôd like to take things a step further, we can manage the Spark server‚Äôs lifecycle entirely in our test suite, ensuring reproducible, specified-in-code, end-to-end dependencies.\nTo do so, we can create a pytest fixture, which is essentially a reusable resource for tests!\nimport docker\n# You can use testcontainers instead of the docker package\n# but I find it a bit bloated and buggy\n# when working with custom images.\n# The docker package is what testcontainers uses\n# behind the scenes, and I find it more consistent.\nimport pytest\nimport time\n\n\n# Utility function:\n# Once the container has produced the desired message, return.\ndef wait_for_log(container, message, timeout=30):\n    start = time.time()\n    while True:\n        logs = container.logs().decode(\"utf-8\")\n        if message in logs:\n            return\n        if time.time() - start &gt; timeout:\n            raise TimeoutError(f\"Message '{message}' not found in logs\")\n        time.sleep(0.5)\n\n\n# The default scope is function,\n# which means the fixture is created and destroyed every test.\n@pytest.fixture(scope=\"function\")\ndef spark_connect_server_url():\n    docker_client = docker.from_env()\n\n    # Let's run a Spark Connect server with a Delta catalog!\n    container = docker_client.containers.run(\n        image=\"franciscoabsampaio/spark-connect-server:delta\",\n        detach=True,\n        ports={'15002/tcp': 15002}\n    )\n    wait_for_log(container, message=\"Spark Connect server started\")\n\n    # Pass the connection string to whoever is using the fixture.\n    yield \"sc://localhost:15002\"\n\n    # Cleanup\n    container.stop()\nNow, we can simply pass the fixture to whichever test requires a running Spark Connect server. For example:\ndef test_basic_read(spark_connect_server_url):  # Use the fixture\n    spark = SparkSession.builder \\\n        .remote(spark_connect_server_url) \\\n        .getOrCreate()\n\n    table_name = \"test_table\"\n\n    # CREATE TABLE USING DELTA\n    spark.sql(f\"\"\"\n        CREATE TABLE {table_name} (\n            id INT,\n            name STRING\n        )\n        USING DELTA\n    \"\"\")\n\n    # INSERT INTO TABLE\n    spark.sql(f\"INSERT INTO {table_name} VALUES (1, 'bird'), (2, 'spark')\")\n\n    # SELECT * FROM TABLE\n    df = spark.sql(f\"SELECT * FROM {table_name} ORDER BY id\")\n    rows = df.collect()\n\n    # Test conditions\n    assert len(rows) == 2\n    assert rows[0][\"id\"] == 1\n    assert rows[0][\"name\"] == \"bird\"\nThe yield statement locks the fixture execution until the test finishes ‚Äî at which point the cleanup code is executed.\n\nAnd that‚Äôs it ‚Äî you now have a fully reproducible, containerized Spark + Delta test setup, ready to integrate into any CI/CD pipeline or local test suite.\nYou can find the container on Docker Hub: üëâ franciscoabsampaio/spark-connect-server\nIf this saved you time (or frustration), give it a ‚≠êÔ∏è on GitHub or share it with your team ‚Äî and let me know what feature you‚Äôd like supported next!\nHappy testing! üöÄ"
  },
  {
    "objectID": "blog/2025-2b-model-at-home/index.html",
    "href": "blog/2025-2b-model-at-home/index.html",
    "title": "Exploring Data with Python",
    "section": "",
    "text": "In this post we‚Äôll do a quick exploration using Python and pandas.\n# Create sample data\nprint(123)\n\n123"
  },
  {
    "objectID": "blog/2025-2b-model-at-home/index.html#activation-checkpoints",
    "href": "blog/2025-2b-model-at-home/index.html#activation-checkpoints",
    "title": "Exploring Data with Python",
    "section": "Activation Checkpoints",
    "text": "Activation Checkpoints\nActivation checkpointing consists of selectively forgetting activations during each training loop, effectively trading off compute for a shallower memory footprint. The concept (expertly presented in this blog post by Bulatov (2018)) is a clever exploitation of dependencies in the model graph that can reduce memory requirements during training from O(n^2) to O(sqrt(n)) - all for the modest cost of an extra forward pass.\nIf we picture the training loop as a directed graph, with each layer‚Äôs activations as nodes on the graph, and activations triggering dependent nodes in a cascading fashion, one way of managing our GPU‚Äôs memory would be to store every node‚Äôs values until a complete pass of the training loop is complete. Clearly, this would not be a good idea if - after all, why store the activations of the first nodes in the graph if we only need the preceding node‚Äôs activations for any given node? It would be much more memory efficient to forget node values as we progress through the graph:\n\n\n\nRich man‚Äôs activation checkpointing (Bulatov 2018).\n\n\nA big problem with training is that the backward pass starts from the loss node (computed from the last node of the forward pass) and moves in reverse order - if we only vacate computed nodes from memory after they‚Äôre no longer needed, we will be keeping a lot of forward pass activations as we walk through the backward pass. The poor man‚Äôs solution would be to forget every node as soon as it is consumed - but this results in a quadratic increase of computations:\n\n\n\nPoor man‚Äôs activation checkpointing (Bulatov 2018).\n\n\nChen et al. (2016) found an effective middle ground: by saving intermediate nodes every sqrt(n) steps - checkpoints - and forgetting all those that won‚Äôt be needed in the next step, the memory footprint can be greatly reduced, for the modest cost of a second forward pass‚Äô worth of compute:\n\n\n\nSmart man‚Äôs activation checkpointing (Bulatov 2018).\n\n\nThis pebble game we‚Äôre playing can get extremely complex (dynamic programming, tree decomposition, etc), but this much will suffice us."
  },
  {
    "objectID": "blog/2025-transformers-maketh-llms/index.html",
    "href": "blog/2025-transformers-maketh-llms/index.html",
    "title": "Transformers Maketh LLMs",
    "section": "",
    "text": "If you haven‚Äôt been living under a rock, you‚Äôve probably noticed that generative AI is the coolest kid on the block.\nSpecifically, large language models (or LLMs) have taken the world by storm, due to how powerful they are at - that‚Äôs right - modelling language, and learning from it.\nThe language modelling problem is not a new one - Chomsky pioneered work in language models way back in the 1950s - and since then (in particular, in the 2000s, following the timely advances in machine learning) people across the world have been trying to invent better ways to model language. The hypothesis was that by learning to accurately model language, computers would gain the ability to perform a series of tasks, due to how expressive and rich with information language intrinsically is.\nBut because we‚Äôre dealing with computers, we need a way to translate this into bits and bytes, or, at the very least, mathematics. The ‚Äúpopular‚Äù way to formulate the problem of modelling language goes like this:\n\nWhat is the probability of a word occurring, given a sequence of words that precedes it?\n\nEssentially, by learning how to predict the next word that makes sense, a model would, by itself, make sense. For the mathematically-curious, what we‚Äôre essentially doing is trying to determine the function that best models:\n\nf(?) = P(word_i | {word_0, ‚Ä¶, word_i-1})\n\nThe traditional way would be to find derive a function that accurately models this behaviour - but given the complexity of language, it‚Äôs near impossible to derive something like this, and intractable to solve (an intractable problem can theoretically be solved, but requires impractical and/or infinite resources to do so)."
  },
  {
    "objectID": "blog/2025-transformers-maketh-llms/index.html#first-a-bit-of-context",
    "href": "blog/2025-transformers-maketh-llms/index.html#first-a-bit-of-context",
    "title": "Transformers Maketh LLMs",
    "section": "",
    "text": "If you haven‚Äôt been living under a rock, you‚Äôve probably noticed that generative AI is the coolest kid on the block.\nSpecifically, large language models (or LLMs) have taken the world by storm, due to how powerful they are at - that‚Äôs right - modelling language, and learning from it.\nThe language modelling problem is not a new one - Chomsky pioneered work in language models way back in the 1950s - and since then (in particular, in the 2000s, following the timely advances in machine learning) people across the world have been trying to invent better ways to model language. The hypothesis was that by learning to accurately model language, computers would gain the ability to perform a series of tasks, due to how expressive and rich with information language intrinsically is.\nBut because we‚Äôre dealing with computers, we need a way to translate this into bits and bytes, or, at the very least, mathematics. The ‚Äúpopular‚Äù way to formulate the problem of modelling language goes like this:\n\nWhat is the probability of a word occurring, given a sequence of words that precedes it?\n\nEssentially, by learning how to predict the next word that makes sense, a model would, by itself, make sense. For the mathematically-curious, what we‚Äôre essentially doing is trying to determine the function that best models:\n\nf(?) = P(word_i | {word_0, ‚Ä¶, word_i-1})\n\nThe traditional way would be to find derive a function that accurately models this behaviour - but given the complexity of language, it‚Äôs near impossible to derive something like this, and intractable to solve (an intractable problem can theoretically be solved, but requires impractical and/or infinite resources to do so)."
  },
  {
    "objectID": "blog/2025-transformers-maketh-llms/index.html#neural-networks",
    "href": "blog/2025-transformers-maketh-llms/index.html#neural-networks",
    "title": "Transformers Maketh LLMs",
    "section": "Neural Networks",
    "text": "Neural Networks\nNeural networks revolutionised machine learning because they allow scientists to brute-force problems. For the unaware, a neural network is, essentially, a somewhat arbitrary combination of non-linear functions, a collection of layers stacked on top of each other, that take inputs and perform weighted averages on them before passing them on to the next layer.\n\n\n\nHigh-level diagram of a neural network.\n\n\n\nThe secret ingredient to neural networks is that every parameter, be it how much we weigh each input, or how we regulate the non-linearity of each layers is learned.\n\n‚ÄúLearned‚Äù is the fancy way of saying the computer tries a bunch of combinations (like, trillions of them) and returns the best result.\nAs you can imagine, as neural networks grow larger (number of variables in each layer) and deeper (number of layers), this becomes an extremely resource-intensive problem - pre-training GPT4 model required more than 20.000 A100 GPUs (each of these is like 10-100 times more powerful than your laptop‚Äôs graphic card!) for 3 months!\nBut ChatGPT isn‚Äôt just a neural network - vanilla neural nets are kind of sucky at taking into account long-distance relationships between words (say, the first and last words of this article), and making them better would be extremely expensive (computationally speaking)."
  },
  {
    "objectID": "blog/2025-transformers-maketh-llms/index.html#the-attention-is-all-you-need-paper",
    "href": "blog/2025-transformers-maketh-llms/index.html#the-attention-is-all-you-need-paper",
    "title": "Transformers Maketh LLMs",
    "section": "The ‚ÄòAttention Is All You Need‚Äô paper",
    "text": "The ‚ÄòAttention Is All You Need‚Äô paper\nIn 2017, when attempting to come up with a better model for machine translation (translation done by computers), Vaswani et. al.¬†presented the ‚ÄúTransformer‚Äù architecture in the now famous ‚ÄúAttention Is All You Need‚Äù paper.\nThe transformer followed the recent introduction of ‚Äúattention‚Äù mechanisms in the field, and took it front and center.\n\nThe attention mechanism is quite intuitive: (put simply) you take a learned numeric representation of each word in the sequence (roughly speaking, the model assigns a number to each word), and you multiply it by every other learned representation of every word in that sequence (a second learned representation). Then, you weigh a third learned representation of the sequence by the result of this product - essentially weighing the sequence by how much each word is related to each other in the sequence.\n\nBecause each numeric representation is learned, the model is given full flexibility over how to represent each word in this not-so-imaginary numerical space, and how important any word is relative to each other!\nI say not-so-imaginary numerical space, because if you then take the learned numerical representations of these words, you will find all sorts of quirky relationships! Famously, here‚Äôs the King - Man + Woman = Queen, and a few more (all images were taken from this awesome video by 3Blue1Brown on YouTube):\n\n\n\nThe learned representation of ‚Äúqueen‚Äù.\n\n\n\n\n\nClosely related words have proximal representations.\n\n\n\n\n\nLikewise, relationships are consistent across many words!\n\n\n\n\n\nüò≥"
  },
  {
    "objectID": "blog/2025-transformers-maketh-llms/index.html#chatgpt",
    "href": "blog/2025-transformers-maketh-llms/index.html#chatgpt",
    "title": "Transformers Maketh LLMs",
    "section": "ChatGPT",
    "text": "ChatGPT\nThe Transformer took the field by storm, and eventually led to ChatGPT, and all these chat assistants we all know.\nThe GPT models are essentially very large transformers, with some sprinkles on top. Which is why - at its core - ChatGPT is a very sophisticated auto-complete, because - following the language modelling reasoning - it‚Äôs simply predicting the next sequence of words, given the user‚Äôs prompt üß†.\nThere are, of course, a few of extra steps that go into making these state-of-the-art word predictors into useful assistants. But it‚Äôs hard to disagree with the statement that the true technical marvel of models like ChatGPT is not the architecture per se, but the sheer dimension of it, which is insanely complex to manage and implement. Not only that, but in order to train a model of this dimension, you need a significant slice of the entire internet."
  },
  {
    "objectID": "blog/2025-transformers-maketh-llms/index.html#life-is-easier-when-you-pay-attention",
    "href": "blog/2025-transformers-maketh-llms/index.html#life-is-easier-when-you-pay-attention",
    "title": "Transformers Maketh LLMs",
    "section": "Life is easier when you pay attention",
    "text": "Life is easier when you pay attention\nIf you‚Äôve been following me, you probably know I‚Äôve been learning about deep learning (ü§∑) by implementing and training these architectures myself.\nTo my surprise, working on the transformer was a breeze! It‚Äôs extremely stable during training, and it just works. Just so you understand - the last model I implemented - the WaveNet - was the complete opposite: a learning experience, yes, but hell nonetheless. The WaveNet took me many tries over the course of a month to make work decently well.\nThe transformer? An afternoon.\nOne difference that stood out is how each architecture models relationships between elements in a sequence - whereas the WaveNet‚Äôs is convoluted and difficult to grasp, transformers just make sense. To me, attention is a very elegant representation of how words relate to each other.\nSo much, that I decided to share it with you üòò"
  },
  {
    "objectID": "blog/2025-transformers-maketh-llms/index.html#next-steps",
    "href": "blog/2025-transformers-maketh-llms/index.html#next-steps",
    "title": "Transformers Maketh LLMs",
    "section": "Next steps",
    "text": "Next steps\nMy future posts are likely to be more technical - so for the non-technical readers, I‚Äôm thankful you‚Äôve paid attention. From here, I will take things up a notch, and attempt to build a BIG (1B+ parameter) model, comparable in size to GPT-2. Much smaller than what we‚Äôve gotten used to (the original ChatGPT was 175B parameters, and the latest models are estimated to be in the trillions!), but big enough to give me a few headaches!\nAs you can imagine, this is a completely different beast, that will require budgeting (training costs ‚Ç¨‚Ç¨‚Ç¨ üí∏), distributed compute (ü•≥), a lot of preliminary testing, and a few dozen academic papers.\nSee you soon!"
  }
]